{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CIFAR-10-CS231n(Open ended Challenge).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOL3If6EFKjuYCOKMpMAsjW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"aPuhwiKlp8VI","colab_type":"code","colab":{}},"source":["import os\n","import tensorflow as tf\n","import numpy as np\n","import math\n","import timeit\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pv9Yno9up-42","colab_type":"code","outputId":"32d2507f-8243-4a38-9e57-a66b8524dc4f","executionInfo":{"status":"ok","timestamp":1585650246379,"user_tz":-330,"elapsed":6182,"user":{"displayName":"SURYA DHEESHJITH","photoUrl":"","userId":"01445913287307819950"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["def load_cifar10(num_training=49000, num_validation=1000, num_test=10000):\n","    \"\"\"\n","    Fetch the CIFAR-10 dataset from the web and perform preprocessing to prepare\n","    it for the two-layer neural net classifier. These are the same steps as\n","    we used for the SVM, but condensed to a single function.\n","    \"\"\"\n","    # Load the raw CIFAR-10 dataset and use appropriate data types and shapes\n","    cifar10 = tf.keras.datasets.cifar10.load_data()\n","    (X_train, y_train), (X_test, y_test) = cifar10\n","    X_train = np.asarray(X_train, dtype=np.float32)\n","    y_train = np.asarray(y_train, dtype=np.int32).flatten()\n","    X_test = np.asarray(X_test, dtype=np.float32)\n","    y_test = np.asarray(y_test, dtype=np.int32).flatten()\n","\n","    # Subsample the data\n","    mask = range(num_training, num_training + num_validation)\n","    X_val = X_train[mask]\n","    y_val = y_train[mask]\n","    mask = range(num_training)\n","    X_train = X_train[mask]\n","    y_train = y_train[mask]\n","    mask = range(num_test)\n","    X_test = X_test[mask]\n","    y_test = y_test[mask]\n","\n","    # Normalize the data: subtract the mean pixel and divide by std\n","    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n","    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n","    X_train = (X_train - mean_pixel) / std_pixel\n","    X_val = (X_val - mean_pixel) / std_pixel\n","    X_test = (X_test - mean_pixel) / std_pixel\n","\n","    return X_train, y_train, X_val, y_val, X_test, y_test\n","\n","# If there are errors with SSL downloading involving self-signed certificates,\n","# it may be that your Python version was recently installed on the current machine.\n","# See: https://github.com/tensorflow/tensorflow/issues/10779\n","# To fix, run the command: /Applications/Python\\ 3.7/Install\\ Certificates.command\n","#   ...replacing paths as necessary.\n","\n","# Invoke the above function to get our data.\n","NHW = (0, 1, 2)\n","X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10()\n","print('Train data shape: ', X_train.shape)\n","print('Train labels shape: ', y_train.shape, y_train.dtype)\n","print('Validation data shape: ', X_val.shape)\n","print('Validation labels shape: ', y_val.shape)\n","print('Test data shape: ', X_test.shape)\n","print('Test labels shape: ', y_test.shape)"],"execution_count":60,"outputs":[{"output_type":"stream","text":["Train data shape:  (49000, 32, 32, 3)\n","Train labels shape:  (49000,) int32\n","Validation data shape:  (1000, 32, 32, 3)\n","Validation labels shape:  (1000,)\n","Test data shape:  (10000, 32, 32, 3)\n","Test labels shape:  (10000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q-FWwSorqBf_","colab_type":"code","colab":{}},"source":["class Dataset(object):\n","    def __init__(self, X, y, batch_size, shuffle=False):\n","        \"\"\"\n","        Construct a Dataset object to iterate over data X and labels y\n","        \n","        Inputs:\n","        - X: Numpy array of data, of any shape\n","        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n","        - batch_size: Integer giving number of elements per minibatch\n","        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n","        \"\"\"\n","        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n","        self.X, self.y = X, y\n","        self.batch_size, self.shuffle = batch_size, shuffle\n","\n","    def __iter__(self):\n","        N, B = self.X.shape[0], self.batch_size\n","        idxs = np.arange(N)\n","        if self.shuffle:\n","            np.random.shuffle(idxs)\n","        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n","\n","\n","train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n","val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n","test_dset = Dataset(X_test, y_test, batch_size=64)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"shf19BtoqGLo","colab_type":"code","outputId":"902a0896-06c4-430a-e088-95072fc936b7","executionInfo":{"status":"ok","timestamp":1585650246380,"user_tz":-330,"elapsed":6150,"user":{"displayName":"SURYA DHEESHJITH","photoUrl":"","userId":"01445913287307819950"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["# We can iterate through a dataset like this:\n","for t, (x, y) in enumerate(train_dset):\n","    print(t, x.shape, y.shape)\n","    if t > 5: break"],"execution_count":62,"outputs":[{"output_type":"stream","text":["0 (64, 32, 32, 3) (64,)\n","1 (64, 32, 32, 3) (64,)\n","2 (64, 32, 32, 3) (64,)\n","3 (64, 32, 32, 3) (64,)\n","4 (64, 32, 32, 3) (64,)\n","5 (64, 32, 32, 3) (64,)\n","6 (64, 32, 32, 3) (64,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S7d7NJ23q1f-","colab_type":"code","colab":{}},"source":["def flatten(x):\n","    \"\"\"    \n","    Input:\n","    - TensorFlow Tensor of shape (N, D1, ..., DM)\n","    \n","    Output:\n","    - TensorFlow Tensor of shape (N, D1 * ... * DM)\n","    \"\"\"\n","    N = tf.shape(x)[0]\n","    return tf.reshape(x, (N, -1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z46xA6cAqagU","colab_type":"code","colab":{}},"source":["def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1, is_training=False):\n","    \"\"\"\n","    Simple training loop for use with models defined using tf.keras. It trains\n","    a model for one epoch on the CIFAR-10 training set and periodically checks\n","    accuracy on the CIFAR-10 validation set.\n","    \n","    Inputs:\n","    - model_init_fn: A function that takes no parameters; when called it\n","      constructs the model we want to train: model = model_init_fn()\n","    - optimizer_init_fn: A function which takes no parameters; when called it\n","      constructs the Optimizer object we will use to optimize the model:\n","      optimizer = optimizer_init_fn()\n","    - num_epochs: The number of epochs to train for\n","    \n","    Returns: Nothing, but prints progress during trainingn\n","    \"\"\"    \n","    with tf.device(device):\n","\n","        # Compute the loss like we did in Part II\n","        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n","        \n","        model = model_init_fn()\n","        optimizer = optimizer_init_fn()\n","        \n","        train_loss = tf.keras.metrics.Mean(name='train_loss')\n","        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","    \n","        val_loss = tf.keras.metrics.Mean(name='val_loss')\n","        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n","        \n","        t = 0\n","        for epoch in range(num_epochs):\n","            \n","            # Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n","            train_loss.reset_states()\n","            train_accuracy.reset_states()\n","            \n","            for x_np, y_np in train_dset:\n","                with tf.GradientTape() as tape:\n","                    \n","                    # Use the model function to build the forward pass.\n","                    scores = model(x_np, training=is_training)\n","                    loss = loss_fn(y_np, scores)\n","      \n","                    gradients = tape.gradient(loss, model.trainable_variables)\n","                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","                    \n","                    # Update the metrics\n","                    train_loss.update_state(loss)\n","                    train_accuracy.update_state(y_np, scores)\n","                    \n","                    if t % print_every == 0:\n","                        val_loss.reset_states()\n","                        val_accuracy.reset_states()\n","                        for test_x, test_y in val_dset:\n","                            # During validation at end of epoch, training set to False\n","                            prediction = model(test_x, training=False)\n","                            t_loss = loss_fn(test_y, prediction)\n","\n","                            val_loss.update_state(t_loss)\n","                            val_accuracy.update_state(test_y, prediction)\n","                        \n","                        template = 'Iteration {}, Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n","                        print (template.format(t, epoch+1,\n","                                             train_loss.result(),\n","                                             train_accuracy.result()*100,\n","                                             val_loss.result(),\n","                                             val_accuracy.result()*100))\n","                    t += 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"48EmHxUu_JM1","colab_type":"text"},"source":["((CONV-BATCH_NORM-RELU)x2 - MAXPOOL) - ((CONV-BATCH_NORM-RELU)x2 - MAXPOOL) - BATCH_NORM - (DENSE-DROPOUT-BATCH_NORM)X4 - DENSE"]},{"cell_type":"code","metadata":{"id":"wNqUVHiPpoIj","colab_type":"code","outputId":"27652cab-b7ed-4c15-b581-1bc694bc055a","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1585647849372,"user_tz":-330,"elapsed":496546,"user":{"displayName":"SURYA DHEESHJITH","photoUrl":"","userId":"01445913287307819950"}}},"source":["class CustomConvNet(tf.keras.Model):\n","    def __init__(self):\n","        super(CustomConvNet, self).__init__()\n","        ############################################################################\n","        # TODO: Construct a model that performs well on CIFAR-10                   #\n","        ############################################################################\n","        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        initializer = tf.initializers.VarianceScaling(scale=2.0)\n","        self.conv1 = tf.keras.layers.Conv2D(64, (3,3), strides = 1, padding='same')\n","        self.norm1 = tf.keras.layers.BatchNormalization()\n","        self.relu1 = tf.keras.layers.ReLU()\n","        self.conv2 = tf.keras.layers.Conv2D(128, (5,5), strides = 1, padding='same')\n","        self.norm2 = tf.keras.layers.BatchNormalization()\n","        self.relu2 = tf.keras.layers.ReLU()\n","        self.pool1 = tf.keras.layers.MaxPool2D((2,2))\n","        \n","        self.conv3 = tf.keras.layers.Conv2D(256, (5,5), strides = 1, padding='same')\n","        self.norm3 = tf.keras.layers.BatchNormalization()\n","        self.relu3 = tf.keras.layers.ReLU()\n","        self.conv4 = tf.keras.layers.Conv2D(512, (5,5), strides = 1, padding='same')\n","        self.norm4 = tf.keras.layers.BatchNormalization()\n","        self.relu4 = tf.keras.layers.ReLU()\n","        self.pool2 = tf.keras.layers.MaxPool2D((2,2))\n","        \n","        \n","        self.norm5 = tf.keras.layers.BatchNormalization()\n","\n","        self.fc1 = tf.keras.layers.Dense(128,activation = tf.nn.relu)\n","        self.drop1 = tf.keras.layers.Dropout(0.3)\n","        self.normf1 = tf.keras.layers.BatchNormalization()\n","        self.fc2 = tf.keras.layers.Dense(256,activation = tf.nn.relu)\n","        self.drop2 = tf.keras.layers.Dropout(0.3)\n","        self.normf2 = tf.keras.layers.BatchNormalization()\n","        self.fc3 = tf.keras.layers.Dense(512,activation = tf.nn.relu)\n","        self.drop3 = tf.keras.layers.Dropout(0.3)\n","        self.normf3 = tf.keras.layers.BatchNormalization()\n","        self.fc4 = tf.keras.layers.Dense(1024, activation = tf.nn.relu)\n","        self.drop4 = tf.keras.layers.Dropout(0.3)\n","        self.normf4 = tf.keras.layers.BatchNormalization()\n","        self.final = tf.keras.layers.Dense(10,activation = 'softmax')\n","        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        ############################################################################\n","        #                            END OF YOUR CODE                              #\n","        ############################################################################\n","    \n","    def call(self, input_tensor, training=False):\n","        ############################################################################\n","        # TODO: Construct a model that performs well on CIFAR-10                   #\n","        ############################################################################\n","        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        #x = tf.keras.applications.resnet50.preprocess_input(input_tensor)\n","        x = self.conv1(input_tensor)\n","        x = self.norm1(x)\n","        x = self.relu1(x)\n","        x = self.conv2(x)\n","        x = self.norm2(x)\n","        x = self.relu2(x)\n","        x = self.pool1(x) \n","\n","        x = self.conv3(x)\n","        x = self.norm3(x)\n","        x = self.relu3(x)\n","        x = self.conv4(x)\n","        x = self.norm4(x)\n","        x = self.relu4(x)\n","        x = self.pool2(x) \n","\n","        x = self.norm5(x)\n","        \n","        x = tf.keras.layers.Flatten()(x)\n","        x = self.fc1(x)\n","        x = self.drop1(x)\n","        x = self.normf1(x)\n","        x = self.fc2(x)\n","        x = self.drop2(x)\n","        x = self.normf2(x)\n","        x = self.fc3(x)\n","        x = self.drop3(x)\n","        x = self.normf3(x)\n","        x = self.fc4(x)\n","        x = self.drop4(x)\n","        x = self.normf4(x)\n","        scores = self.final(x)\n","        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        ############################################################################\n","        #                            END OF YOUR CODE                              #\n","        ############################################################################\n","        \n","        return scores\n","\n","device = '/device:GPU:0'   # Change this to a CPU/GPU as you wish!\n","# device = '/cpu:0'        # Change this to a CPU/GPU as you wish!\n","print_every = 700\n","num_epochs = 10\n","\n","model = CustomConvNet()\n","\n","def model_init_fn():\n","    return CustomConvNet()\n","\n","def optimizer_init_fn():\n","    learning_rate = 1e-3\n","    return tf.keras.optimizers.Adam(learning_rate) \n","\n","train_part34(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, is_training=True)"],"execution_count":49,"outputs":[{"output_type":"stream","text":["Iteration 0, Epoch 1, Loss: 2.89121675491333, Accuracy: 4.6875, Val Loss: 2.3063817024230957, Val Accuracy: 11.100000381469727\n","Iteration 700, Epoch 1, Loss: 1.8064565658569336, Accuracy: 37.836570739746094, Val Loss: 1.3094923496246338, Val Accuracy: 54.400001525878906\n","Iteration 1400, Epoch 2, Loss: 1.1325888633728027, Accuracy: 60.268211364746094, Val Loss: 0.9962601661682129, Val Accuracy: 65.5999984741211\n","Iteration 2100, Epoch 3, Loss: 0.9067550301551819, Accuracy: 68.83512878417969, Val Loss: 0.8226927518844604, Val Accuracy: 71.10000610351562\n","Iteration 2800, Epoch 4, Loss: 0.7414024472236633, Accuracy: 74.81050872802734, Val Loss: 0.9280353784561157, Val Accuracy: 68.69999694824219\n","Iteration 3500, Epoch 5, Loss: 0.6234967708587646, Accuracy: 78.99027252197266, Val Loss: 0.6712948679924011, Val Accuracy: 77.9000015258789\n","Iteration 4200, Epoch 6, Loss: 0.5162390470504761, Accuracy: 82.65666961669922, Val Loss: 0.7679693698883057, Val Accuracy: 75.5\n","Iteration 4900, Epoch 7, Loss: 0.416521281003952, Accuracy: 86.14241790771484, Val Loss: 0.7489559650421143, Val Accuracy: 77.60000610351562\n","Iteration 5600, Epoch 8, Loss: 0.32030484080314636, Accuracy: 89.27824401855469, Val Loss: 0.6929941177368164, Val Accuracy: 78.89999389648438\n","Iteration 6300, Epoch 9, Loss: 0.2572024464607239, Accuracy: 91.24819946289062, Val Loss: 0.6463640928268433, Val Accuracy: 80.69999694824219\n","Iteration 7000, Epoch 10, Loss: 0.18707428872585297, Accuracy: 94.10047149658203, Val Loss: 0.8554635047912598, Val Accuracy: 77.80000305175781\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yr4nJjmN_rHB","colab_type":"text"},"source":["((CONV-RELU-BATCH_NORM)x2 - MAXPOOL) - ((CONV-RELU-BATCH_NORM)x2 - MAXPOOL) - BATCH_NORM - (DENSE-DROPOUT-BATCH_NORM)X4 - DENSE"]},{"cell_type":"code","metadata":{"id":"r5eEwE6LsOEC","colab_type":"code","colab":{}},"source":["class CustomConvNet2(tf.keras.Model):\n","    def __init__(self):\n","        super(CustomConvNet2, self).__init__()\n","        ############################################################################\n","        # TODO: Construct a model that performs well on CIFAR-10                   #\n","        ############################################################################\n","        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        initializer = tf.initializers.VarianceScaling(scale=2.0)\n","        self.conv1 = tf.keras.layers.Conv2D(64, (3,3), strides = 1, padding='same')\n","        self.relu1 = tf.keras.layers.ReLU()\n","        self.norm1 = tf.keras.layers.BatchNormalization()\n","        self.conv2 = tf.keras.layers.Conv2D(128, (5,5), strides = 1, padding='same')\n","        self.relu2 = tf.keras.layers.ReLU()\n","        self.norm2 = tf.keras.layers.BatchNormalization()\n","        self.pool1 = tf.keras.layers.MaxPool2D((2,2))\n","        \n","        self.conv3 = tf.keras.layers.Conv2D(256, (5,5), strides = 1, padding='same')\n","        self.relu3 = tf.keras.layers.ReLU()\n","        self.norm3 = tf.keras.layers.BatchNormalization()\n","        self.conv4 = tf.keras.layers.Conv2D(512, (5,5), strides = 1, padding='same')\n","        self.relu4 = tf.keras.layers.ReLU()\n","        self.norm4 = tf.keras.layers.BatchNormalization()\n","        self.pool2 = tf.keras.layers.MaxPool2D((2,2))\n","        \n","        \n","        self.norm5 = tf.keras.layers.BatchNormalization()\n","\n","        self.fc1 = tf.keras.layers.Dense(128,activation = tf.nn.relu)\n","        self.drop1 = tf.keras.layers.Dropout(0.3)\n","        self.normf1 = tf.keras.layers.BatchNormalization()\n","        self.fc2 = tf.keras.layers.Dense(256,activation = tf.nn.relu)\n","        self.drop2 = tf.keras.layers.Dropout(0.3)\n","        self.normf2 = tf.keras.layers.BatchNormalization()\n","        self.fc3 = tf.keras.layers.Dense(512,activation = tf.nn.relu)\n","        self.drop3 = tf.keras.layers.Dropout(0.3)\n","        self.normf3 = tf.keras.layers.BatchNormalization()\n","        self.fc4 = tf.keras.layers.Dense(1024, activation = tf.nn.relu)\n","        self.drop4 = tf.keras.layers.Dropout(0.3)\n","        self.normf4 = tf.keras.layers.BatchNormalization()\n","        self.final = tf.keras.layers.Dense(10,activation = 'softmax')\n","        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        ############################################################################\n","        #                            END OF YOUR CODE                              #\n","        ############################################################################\n","    \n","    def call(self, input_tensor, training=False):\n","        ############################################################################\n","        # TODO: Construct a model that performs well on CIFAR-10                   #\n","        ############################################################################\n","        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        #x = tf.keras.applications.resnet50.preprocess_input(input_tensor)\n","        x = self.conv1(input_tensor)\n","        x = self.relu1(x)\n","        x = self.norm1(x)\n","        x = self.conv2(x)\n","        x = self.relu2(x)\n","        x = self.norm2(x)\n","        x = self.pool1(x) \n","\n","        x = self.conv3(x)\n","        x = self.relu3(x)\n","        x = self.norm3(x)\n","        x = self.conv4(x)\n","        x = self.relu4(x)\n","        x = self.norm4(x)\n","        x = self.pool2(x) \n","\n","        x = self.norm5(x)\n","        \n","        x = tf.keras.layers.Flatten()(x)\n","        x = self.fc1(x)\n","        x = self.drop1(x)\n","        x = self.normf1(x)\n","        x = self.fc2(x)\n","        x = self.drop2(x)\n","        x = self.normf2(x)\n","        x = self.fc3(x)\n","        x = self.drop3(x)\n","        x = self.normf3(x)\n","        x = self.fc4(x)\n","        x = self.drop4(x)\n","        x = self.normf4(x)\n","        scores = self.final(x)\n","        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        ############################################################################\n","        #                            END OF YOUR CODE                              #\n","        ############################################################################\n","        \n","        return scores\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wtdRl_OP94tn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"ee22bbbd-3a28-4208-bc04-0785e2d173b2","executionInfo":{"status":"ok","timestamp":1585648423401,"user_tz":-330,"elapsed":501721,"user":{"displayName":"SURYA DHEESHJITH","photoUrl":"","userId":"01445913287307819950"}}},"source":["\n","device = '/device:GPU:0'   # Change this to a CPU/GPU as you wish!\n","# device = '/cpu:0'        # Change this to a CPU/GPU as you wish!\n","print_every = 700\n","num_epochs = 10\n","\n","model = CustomConvNet2()\n","\n","def model_init_fn():\n","    return CustomConvNet2()\n","\n","def optimizer_init_fn():\n","    learning_rate = 1e-3\n","    return tf.keras.optimizers.Adam(learning_rate) \n","\n","train_part34(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, is_training=True)"],"execution_count":51,"outputs":[{"output_type":"stream","text":["Iteration 0, Epoch 1, Loss: 3.045879364013672, Accuracy: 7.8125, Val Loss: 2.2978439331054688, Val Accuracy: 13.699999809265137\n","Iteration 700, Epoch 1, Loss: 1.7242741584777832, Accuracy: 40.84789276123047, Val Loss: 1.2221026420593262, Val Accuracy: 57.0\n","Iteration 1400, Epoch 2, Loss: 1.029404640197754, Accuracy: 64.39960479736328, Val Loss: 0.8286232352256775, Val Accuracy: 70.9000015258789\n","Iteration 2100, Epoch 3, Loss: 0.7759090662002563, Accuracy: 73.769775390625, Val Loss: 0.8225467205047607, Val Accuracy: 72.29999542236328\n","Iteration 2800, Epoch 4, Loss: 0.5957204699516296, Accuracy: 80.17208862304688, Val Loss: 0.7292961478233337, Val Accuracy: 77.5\n","Iteration 3500, Epoch 5, Loss: 0.46390238404273987, Accuracy: 84.58595275878906, Val Loss: 0.6513972282409668, Val Accuracy: 79.69999694824219\n","Iteration 4200, Epoch 6, Loss: 0.34749653935432434, Accuracy: 88.64555358886719, Val Loss: 0.6391110420227051, Val Accuracy: 80.4000015258789\n","Iteration 4900, Epoch 7, Loss: 0.25587233901023865, Accuracy: 91.83914184570312, Val Loss: 0.73403000831604, Val Accuracy: 80.19999694824219\n","Iteration 5600, Epoch 8, Loss: 0.18408747017383575, Accuracy: 94.2533950805664, Val Loss: 0.7413180470466614, Val Accuracy: 81.0\n","Iteration 6300, Epoch 9, Loss: 0.14826509356498718, Accuracy: 95.10476684570312, Val Loss: 0.7290468215942383, Val Accuracy: 82.0\n","Iteration 7000, Epoch 10, Loss: 0.12920482456684113, Accuracy: 95.8674087524414, Val Loss: 0.7643614411354065, Val Accuracy: 81.5999984741211\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nzXWxavgA1t3","colab_type":"code","colab":{}},"source":["class CustomConvNet3(tf.keras.Model):\n","    def __init__(self):\n","        super(CustomConvNet3, self).__init__()\n","        ############################################################################\n","        # TODO: Construct a model that performs well on CIFAR-10                   #\n","        ############################################################################\n","        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        initializer = tf.initializers.VarianceScaling(scale=2.0)\n","        self.conv1 = tf.keras.layers.Conv2D(64, (3,3), strides = 1, padding='same')\n","        self.relu1 = tf.keras.layers.ReLU()\n","        self.norm1 = tf.keras.layers.BatchNormalization()\n","        self.conv2 = tf.keras.layers.Conv2D(128, (5,5), strides = 1, padding='same')\n","        self.relu2 = tf.keras.layers.ReLU()\n","        self.norm2 = tf.keras.layers.BatchNormalization()\n","        self.pool1 = tf.keras.layers.MaxPool2D((2,2))\n","        \n","        self.conv3 = tf.keras.layers.Conv2D(256, (5,5), strides = 1, padding='same')\n","        self.relu3 = tf.keras.layers.ReLU()\n","        self.norm3 = tf.keras.layers.BatchNormalization()\n","        self.conv4 = tf.keras.layers.Conv2D(512, (5,5), strides = 1, padding='same')\n","        self.relu4 = tf.keras.layers.ReLU()\n","        self.norm4 = tf.keras.layers.BatchNormalization()\n","        self.pool2 = tf.keras.layers.MaxPool2D((2,2))\n","        \n","        \n","        self.norm5 = tf.keras.layers.BatchNormalization()\n","\n","        self.fc1 = tf.keras.layers.Dense(128,activation = tf.nn.relu)\n","        self.drop1 = tf.keras.layers.Dropout(0.3)\n","        self.normf1 = tf.keras.layers.BatchNormalization()\n","        self.fc2 = tf.keras.layers.Dense(256,activation = tf.nn.relu)\n","        self.drop2 = tf.keras.layers.Dropout(0.3)\n","        self.normf2 = tf.keras.layers.BatchNormalization()\n","\n","        self.final = tf.keras.layers.Dense(10,activation = 'softmax')\n","        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        ############################################################################\n","        #                            END OF YOUR CODE                              #\n","        ############################################################################\n","    \n","    def call(self, input_tensor, training=False):\n","        ############################################################################\n","        # TODO: Construct a model that performs well on CIFAR-10                   #\n","        ############################################################################\n","        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        #x = tf.keras.applications.resnet50.preprocess_input(input_tensor)\n","        x = self.conv1(input_tensor)\n","        x = self.relu1(x)\n","        x = self.norm1(x)\n","        x = self.conv2(x)\n","        x = self.relu2(x)\n","        x = self.norm2(x)\n","        x = self.pool1(x) \n","\n","        x = self.conv3(x)\n","        x = self.relu3(x)\n","        x = self.norm3(x)\n","        x = self.conv4(x)\n","        x = self.relu4(x)\n","        x = self.norm4(x)\n","        x = self.pool2(x) \n","\n","        x = self.norm5(x)\n","        \n","        x = tf.keras.layers.Flatten()(x)\n","        x = self.fc1(x)\n","        x = self.drop1(x)\n","        x = self.normf1(x)\n","        x = self.fc2(x)\n","        x = self.drop2(x)\n","        x = self.normf2(x)\n","\n","        scores = self.final(x)\n","        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        ############################################################################\n","        #                            END OF YOUR CODE                              #\n","        ############################################################################\n","        \n","        return scores\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CoIOLGgqA17M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"ba5178d6-cad3-4bbf-ca8c-47833141bed1","executionInfo":{"status":"ok","timestamp":1585650231011,"user_tz":-330,"elapsed":191000,"user":{"displayName":"SURYA DHEESHJITH","photoUrl":"","userId":"01445913287307819950"}}},"source":["\n","device = '/device:GPU:0'   # Change this to a CPU/GPU as you wish!\n","# device = '/cpu:0'        # Change this to a CPU/GPU as you wish!\n","print_every = 700\n","num_epochs = 10\n","\n","model = CustomConvNet3()\n","\n","def model_init_fn():\n","    return CustomConvNet3()\n","\n","def optimizer_init_fn():\n","    learning_rate = 1e-3\n","    return tf.keras.optimizers.Adam(learning_rate) \n","\n","train_part34(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, is_training=True)"],"execution_count":58,"outputs":[{"output_type":"stream","text":["Iteration 0, Epoch 1, Loss: 3.192493438720703, Accuracy: 7.8125, Val Loss: 2.295973777770996, Val Accuracy: 11.300000190734863\n","Iteration 700, Epoch 1, Loss: 1.4527169466018677, Accuracy: 48.78744888305664, Val Loss: 0.9365317225456238, Val Accuracy: 67.29999542236328\n","Iteration 1400, Epoch 2, Loss: 0.8530118465423584, Accuracy: 70.24360656738281, Val Loss: 0.7477878928184509, Val Accuracy: 71.4000015258789\n","Iteration 2100, Epoch 3, Loss: 0.6241518259048462, Accuracy: 78.59732055664062, Val Loss: 0.7351481914520264, Val Accuracy: 74.69999694824219\n","Iteration 2800, Epoch 4, Loss: 0.447843998670578, Accuracy: 84.87822723388672, Val Loss: 0.624416708946228, Val Accuracy: 79.29999542236328\n","Iteration 3500, Epoch 5, Loss: 0.3144620656967163, Accuracy: 89.22697448730469, Val Loss: 0.6183016300201416, Val Accuracy: 80.9000015258789\n","Iteration 4200, Epoch 6, Loss: 0.2203754037618637, Accuracy: 92.38544464111328, Val Loss: 0.6192266941070557, Val Accuracy: 82.4000015258789\n","Iteration 4900, Epoch 7, Loss: 0.15345370769500732, Accuracy: 94.72848510742188, Val Loss: 0.6770477294921875, Val Accuracy: 81.80000305175781\n","Iteration 5600, Epoch 8, Loss: 0.10933215171098709, Accuracy: 96.45005798339844, Val Loss: 0.7185346484184265, Val Accuracy: 82.30000305175781\n","Iteration 6300, Epoch 9, Loss: 0.08536602556705475, Accuracy: 97.0104751586914, Val Loss: 0.6740651726722717, Val Accuracy: 83.20000457763672\n","Iteration 7000, Epoch 10, Loss: 0.079840287566185, Accuracy: 97.4299087524414, Val Loss: 0.684828519821167, Val Accuracy: 83.4000015258789\n"],"name":"stdout"}]}]}